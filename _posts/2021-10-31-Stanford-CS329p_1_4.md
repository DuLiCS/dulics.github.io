---


layout: post
title: CS 329P:Practical Machine Learning(2021 Fall)
subtitle: 1.4 Data Labeling
tags: [Machine Learning, Course]

---

<head>
    <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>
    <script type="text/x-mathjax-config">
        MathJax.Hub.Config({
            tex2jax: {
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
            inlineMath: [['$','$']]
            }
        });
    </script>
</head>



## 1.4 Data Labeling

### 1.4.1 Semi-Supervised Learning(SSL)

* Focus on the scenario where there is a small amount of labeled data,along with a large amount of unlabeled data.
* Make assumptions on data distribution to use unlabeled data
	* Continuity assumption
	* Cluster assumption
	* Manifold assumption
* Self-training

![](/img/Self_training_flow.PNG)

* We can use expensive models like deep neural network,model ensemble/bagging

### 1.4.2 Label through Crowsourcing

* Challenges
	* Simplify user interaction
	* Qulity control
	* Cost

### 1.4.3 Active Learning + Self-training

![](/img/active_learning_self_training.PNG)

### 1.4.4 Quality Control

### 1.4.5 Weak Supervision

* Semi-automatically generate labels
	* Less accurate than manual ones,but good enough for training
* Data programming